{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d076862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b979ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0861f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuración:\n",
      "   batch_size: 64\n",
      "   num_epochs: 100\n",
      "   output_dir: mlp_results_opt\n",
      "   use_augmentation: True\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 100,\n",
    "        'output_dir': 'mlp_results_opt',\n",
    "        'use_augmentation': True  #Cambiar a False si no se quiere augmentation\n",
    "    }\n",
    "\n",
    "print(f\"\\nConfiguración:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37053b51",
   "metadata": {},
   "source": [
    "## MLP SIN FEATURE EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f481c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_pixel_data(prefix='covid19_raw_opt'):\n",
    "    \"\"\"Carga datos de píxeles crudos optimizados\"\"\"\n",
    "    print(f\"\\nCargando datos RAW\")\n",
    "    \n",
    "    X_train = np.load(f'{prefix}_X_train.npy')\n",
    "    X_val = np.load(f'{prefix}_X_val.npy')\n",
    "    X_test = np.load(f'{prefix}_X_test.npy')\n",
    "    y_train = np.load(f'{prefix}_y_train.npy')\n",
    "    y_val = np.load(f'{prefix}_y_val.npy')\n",
    "    y_test = np.load(f'{prefix}_y_test.npy')\n",
    "    \n",
    "    print(f\"   Train: {X_train.shape}\")\n",
    "    print(f\"   Val:   {X_val.shape}\")\n",
    "    print(f\"   Test:  {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb1147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando datos RAW\n",
      "   Train: (28536, 16384)\n",
      "   Val:   (6116, 16384)\n",
      "   Test:  (6116, 16384)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_val_raw, X_test_raw, y_train_raw, y_val_raw, y_test_raw = \\\n",
    "        load_raw_pixel_data('covid19_raw_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774e401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=64):\n",
    "    \"\"\"Prepara DataLoaders de PyTorch\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    y_val_encoded = le.transform(y_val)\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    \n",
    "    y_train_tensor = torch.LongTensor(y_train_encoded)\n",
    "    y_val_tensor = torch.LongTensor(y_val_encoded)\n",
    "    y_test_tensor = torch.LongTensor(y_test_encoded)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nDataLoaders creados (batch_size={batch_size})\")\n",
    "    print(f\"   Train batches: {len(train_loader)}\")\n",
    "    print(f\"   Val batches:   {len(val_loader)}\")\n",
    "    print(f\"   Test batches:  {len(test_loader)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ba5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Shallow(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura Shallow\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP_Shallow, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(384, 192),\n",
    "            nn.BatchNorm1d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(192, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb38f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Medium(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura Medium\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP_Medium, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "995caae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Deep_Regularized(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitectura Deep \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP_Deep_Regularized, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            \n",
    "            nn.Linear(768, 384),\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(384, 192),\n",
    "            nn.BatchNorm1d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(192, 96),\n",
    "            nn.BatchNorm1d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(96, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5f61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Valida el modelo\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79cd9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_batch(X_batch, img_size=128, augmentation_probability=0.3):\n",
    "    \"\"\"\n",
    "    Aplica data augmentation on-the-fly durante entrenamiento\n",
    "    \n",
    "    Solo para datos RAW (píxeles), no para LBP\n",
    "    \"\"\"\n",
    "    X_aug = X_batch.clone()\n",
    "    batch_size, features = X_aug.shape\n",
    "    \n",
    "    # Verificar que el tamaño es correcto\n",
    "    if features != img_size * img_size:\n",
    "        return X_aug  # No augmentar si no es una imagen cuadrada\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        if np.random.rand() < augmentation_probability:\n",
    "            # Reshape a imagen\n",
    "            img = X_aug[i].reshape(img_size, img_size).cpu().numpy()\n",
    "            \n",
    "            # Aplicar transformación aleatoria\n",
    "            aug_type = np.random.choice([\n",
    "                'rotate', 'flip', 'shift', 'noise', 'brightness'\n",
    "            ])\n",
    "            \n",
    "            if aug_type == 'rotate':\n",
    "                angle = np.random.uniform(-10, 10)\n",
    "                M = cv2.getRotationMatrix2D((img_size/2, img_size/2), angle, 1.0)\n",
    "                img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REFLECT)\n",
    "            \n",
    "            elif aug_type == 'flip':\n",
    "                img = np.fliplr(img)\n",
    "            \n",
    "            elif aug_type == 'shift':\n",
    "                shift_x = int(np.random.uniform(-5, 5))\n",
    "                shift_y = int(np.random.uniform(-5, 5))\n",
    "                M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "                img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REFLECT)\n",
    "            \n",
    "            elif aug_type == 'noise':\n",
    "                noise = np.random.normal(0, 0.05, img.shape)\n",
    "                img = img + noise\n",
    "            \n",
    "            elif aug_type == 'brightness':\n",
    "                factor = np.random.uniform(0.9, 1.1)\n",
    "                img = img * factor\n",
    "            \n",
    "            # Volver a aplanar\n",
    "            X_aug[i] = torch.from_numpy(img.flatten().astype(np.float32))\n",
    "    \n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, \n",
    "                         use_augmentation=False, img_size=128):\n",
    "    \"\"\"\n",
    "    Entrena el modelo por una época\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Aplicar augmentation si está habilitado\n",
    "        if use_augmentation:\n",
    "            inputs = get_augmented_batch(inputs, img_size, augmentation_probability=0.3)\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping para estabilidad\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f725d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, device, \n",
    "                         model_name, use_augmentation=False, img_size=128):\n",
    "    \"\"\"\n",
    "    Entrena el modelo\n",
    "    \"\"\"\n",
    "    print(f\"\\nEntrenando {model_name}\")\n",
    "    \n",
    "    # Criterio con label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    # AdamW con weight decay más fuerte\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=0.001,\n",
    "        weight_decay=1e-4  # Era 1e-5\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler: Reduce on plateau\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',\n",
    "        factor=0.5,\n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    patience = 15\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device,\n",
    "            use_augmentation, img_size\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Guardar historial\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Print cada 5 épocas\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1:3d}/{num_epochs}] | \"\n",
    "                  f\"Train: {train_loss:.4f}/{train_acc:.4f} | \"\n",
    "                  f\"Val: {val_loss:.4f}/{val_acc:.4f} | \"\n",
    "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping en época {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(f\"\\n✓ Entrenamiento completado en {training_time:.2f}s\")\n",
    "    print(f\"  Mejor Val Accuracy: {best_val_acc:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return model, history, training_time, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23bb2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, label_encoder):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de test\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            outputs = model(inputs)\n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    all_preds = label_encoder.inverse_transform(all_preds)\n",
    "    all_labels = label_encoder.inverse_transform(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=label_encoder.classes_)\n",
    "    \n",
    "    avg_inference_time = np.mean(inference_times) * 1000\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'precision_per_class': precision_per_class,\n",
    "        'recall_per_class': recall_per_class,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'confusion_matrix': cm,\n",
    "        'avg_inference_time_ms': avg_inference_time,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c55e3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics, class_names, model_name):\n",
    "    \"\"\"Imprime métricas de forma legible\"\"\"\n",
    "    print(f\"\\nMétricas de {model_name}\")\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"Inference: {metrics['avg_inference_time_ms']:.2f} ms/batch\")\n",
    "    \n",
    "    print(f\"\\nMétricas por clase:\")\n",
    "    print(f\"{'Clase':<25} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<25} \"\n",
    "              f\"{metrics['precision_per_class'][i]:<12.4f} \"\n",
    "              f\"{metrics['recall_per_class'][i]:<12.4f} \"\n",
    "              f\"{metrics['f1_per_class'][i]:<12.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794d09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name, save_path):\n",
    "    \"\"\"Grafica el historial de entrenamiento\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('Época', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title(f'{model_name} - Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    axes[1].set_xlabel('Época', fontsize=12)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[1].set_title(f'{model_name} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[2].plot(epochs, history['lr'], 'g-', linewidth=2)\n",
    "    axes[2].set_xlabel('Época', fontsize=12)\n",
    "    axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[2].set_title(f'{model_name} - Learning Rate', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Gráfica guardada: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name, save_path):\n",
    "    \"\"\"Grafica la matriz de confusión\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Proporción'})\n",
    "    \n",
    "    plt.title(f'{model_name} - Matriz de Confusión (Normalizada)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.ylabel('Etiqueta Real', fontsize=12)\n",
    "    plt.xlabel('Etiqueta Predicha', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Matriz de confusión guardada: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_comparison_table(results_df, save_path):\n",
    "    \"\"\"Crea tabla comparativa de todos los modelos\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(16, len(results_df) * 0.8))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        table_data.append([\n",
    "            row['Modelo'],\n",
    "            f\"{row['Accuracy']:.4f}\",\n",
    "            f\"{row['Precision']:.4f}\",\n",
    "            f\"{row['Recall']:.4f}\",\n",
    "            f\"{row['F1-Score']:.4f}\",\n",
    "            f\"{row['Train Time (s)']:.2f}\",\n",
    "            f\"{row['Inference (ms)']:.2f}\",\n",
    "            f\"{row['Params']:,}\"\n",
    "        ])\n",
    "    \n",
    "    columns = ['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1-Score', \n",
    "               'Train Time (s)', 'Inference (ms)', 'Parámetros']\n",
    "    \n",
    "    table = ax.table(cellText=table_data, colLabels=columns,\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.20, 0.10, 0.10, 0.10, 0.10, 0.12, 0.12, 0.12])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    for i in range(len(columns)):\n",
    "        table[(0, i)].set_facecolor('#4472C4')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    for i in range(1, len(table_data) + 1):\n",
    "        if i % 2 == 0:\n",
    "            for j in range(len(columns)):\n",
    "                table[(i, j)].set_facecolor('#F0F0F0')\n",
    "    \n",
    "    plt.title('Comparación de Modelos MLP OPTIMIZADOS', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Tabla comparativa guardada: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f67ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_architectures(X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "                                     data_type, batch_size=64, num_epochs=100, \n",
    "                                     output_dir='results_opt', use_augmentation=False):\n",
    "    \"\"\"\n",
    "    Entrena todas las arquitecturas OPTIMIZADAS\n",
    "    \"\"\"\n",
    "    print(f\"Entrenando modelos MLP - {data_type.upper()}\")\n",
    "    \n",
    "    output_path = Path(output_dir) / data_type\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, le = prepare_dataloaders(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, batch_size\n",
    "    )\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    num_classes = len(le.classes_)\n",
    "    class_names = le.classes_\n",
    "    \n",
    "    # Determinar img_size para augmentation\n",
    "    img_size = int(np.sqrt(input_size)) if input_size == 128*128 else 0\n",
    "    \n",
    "    print(f\"\\nConfiguración:\")\n",
    "    print(f\"   Input size: {input_size}\")\n",
    "    print(f\"   Num classes: {num_classes}\")\n",
    "    print(f\"   Classes: {list(class_names)}\")\n",
    "    print(f\"   Data augmentation: {'Enabled' if use_augmentation and img_size > 0 else '✗ Disabled'}\")\n",
    "    \n",
    "    # Definir arquitecturas OPTIMIZADAS\n",
    "    architectures = {\n",
    "        f'{data_type}_shallow': MLP_Shallow(input_size, num_classes),\n",
    "        f'{data_type}_medium': MLP_Medium(input_size, num_classes),\n",
    "        f'{data_type}_deep_regularized': MLP_Deep_Regularized(input_size, num_classes)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_name, model in architectures.items():\n",
    "        print(f\"Arquitectura: {model_name}\")\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"   Parámetros entrenables: {num_params:,}\")\n",
    "        \n",
    "        # Entrenar con optimizaciones\n",
    "        model, history, train_time, best_val_acc = train_model(\n",
    "            model, train_loader, val_loader, num_epochs, device, model_name,\n",
    "            use_augmentation=(use_augmentation and img_size > 0), img_size=img_size\n",
    "        )\n",
    "        \n",
    "        # Evaluar\n",
    "        metrics = evaluate_model(model, test_loader, device, le)\n",
    "        \n",
    "        print_metrics(metrics, class_names, model_name)\n",
    "        \n",
    "        # Guardar modelo\n",
    "        model_path = output_path / f'{model_name}.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'input_size': input_size,\n",
    "            'num_classes': num_classes,\n",
    "            'class_names': list(class_names),\n",
    "            'label_encoder': le,\n",
    "            'metrics': metrics,\n",
    "            'history': history\n",
    "        }, model_path)\n",
    "        print(f\"\\nModelo guardado: {model_path}\")\n",
    "        \n",
    "        # Visualizaciones\n",
    "        plot_training_history(history, model_name, \n",
    "                            output_path / f'{model_name}_history.png')\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], class_names, model_name,\n",
    "                            output_path / f'{model_name}_confusion.png')\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results.append({\n",
    "            'Modelo': model_name,\n",
    "            'Accuracy': metrics['accuracy'],\n",
    "            'Precision': metrics['precision'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'F1-Score': metrics['f1'],\n",
    "            'Train Time (s)': train_time,\n",
    "            'Inference (ms)': metrics['avg_inference_time_ms'],\n",
    "            'Params': num_params,\n",
    "            'Best Val Acc': best_val_acc\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "    \n",
    "    csv_path = output_path / 'comparison.csv'\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nResultados guardados: {csv_path}\")\n",
    "    \n",
    "    plot_comparison_table(results_df, output_path / 'comparison_table.png')\n",
    "    \n",
    "    print(f\"RESUMEN - {data_type.upper()}\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "814ed210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelos MLP - RAW\n",
      "\n",
      "DataLoaders creados (batch_size=64)\n",
      "   Train batches: 446\n",
      "   Val batches:   96\n",
      "   Test batches:  96\n",
      "\n",
      "Configuración:\n",
      "   Input size: 16384\n",
      "   Num classes: 4\n",
      "   Classes: [np.str_('COVID'), np.str_('Lung_Opacity'), np.str_('Normal'), np.str_('Viral Pneumonia')]\n",
      "   Data augmentation: Enabled\n",
      "Arquitectura: raw_shallow\n",
      "   Parámetros entrenables: 6,367,684\n",
      "\n",
      "Entrenando raw_shallow\n",
      "Epoch [  5/100] | Train: 0.6822/0.8275 | Val: 0.6545/0.8396 | LR: 0.001000\n",
      "Epoch [ 10/100] | Train: 0.6179/0.8675 | Val: 0.6215/0.8592 | LR: 0.001000\n",
      "Epoch [ 15/100] | Train: 0.5754/0.8928 | Val: 0.5926/0.8733 | LR: 0.001000\n",
      "Epoch [ 20/100] | Train: 0.5425/0.9158 | Val: 0.5855/0.8818 | LR: 0.001000\n",
      "Epoch [ 25/100] | Train: 0.5229/0.9261 | Val: 0.5774/0.8887 | LR: 0.001000\n",
      "Epoch [ 30/100] | Train: 0.5049/0.9363 | Val: 0.5752/0.8896 | LR: 0.001000\n",
      "Epoch [ 35/100] | Train: 0.4994/0.9400 | Val: 0.5706/0.8900 | LR: 0.000500\n",
      "Epoch [ 40/100] | Train: 0.4726/0.9564 | Val: 0.5673/0.8932 | LR: 0.000500\n",
      "Epoch [ 45/100] | Train: 0.4612/0.9606 | Val: 0.5603/0.8967 | LR: 0.000250\n",
      "Epoch [ 50/100] | Train: 0.4561/0.9637 | Val: 0.5638/0.8965 | LR: 0.000250\n",
      "Epoch [ 55/100] | Train: 0.4520/0.9652 | Val: 0.5612/0.8944 | LR: 0.000125\n",
      "Epoch [ 60/100] | Train: 0.4473/0.9685 | Val: 0.5587/0.8962 | LR: 0.000125\n",
      "\n",
      "Early stopping en época 64\n",
      "\n",
      "✓ Entrenamiento completado en 172.73s\n",
      "  Mejor Val Accuracy: 0.8980\n",
      "======================================================================\n",
      "\n",
      "Métricas de raw_shallow\n",
      "Accuracy:  0.9011\n",
      "Precision: 0.9007\n",
      "Recall:    0.9011\n",
      "F1-Score:  0.9007\n",
      "Inference: 0.28 ms/batch\n",
      "\n",
      "Métricas por clase:\n",
      "Clase                     Precision    Recall       F1-Score    \n",
      "COVID                     0.8836       0.8986       0.8911      \n",
      "Lung_Opacity              0.8784       0.8358       0.8566      \n",
      "Normal                    0.8660       0.8790       0.8724      \n",
      "Viral Pneumonia           0.9749       0.9908       0.9828      \n",
      "\n",
      "Modelo guardado: mlp_results_opt\\raw\\raw_shallow.pth\n",
      "Gráfica guardada: mlp_results_opt\\raw\\raw_shallow_history.png\n",
      "Matriz de confusión guardada: mlp_results_opt\\raw\\raw_shallow_confusion.png\n",
      "Arquitectura: raw_medium\n",
      "   Parámetros entrenables: 8,555,652\n",
      "\n",
      "Entrenando raw_medium\n",
      "Epoch [  5/100] | Train: 0.7090/0.8103 | Val: 0.6531/0.8376 | LR: 0.001000\n",
      "Epoch [ 10/100] | Train: 0.6509/0.8470 | Val: 0.6140/0.8602 | LR: 0.001000\n",
      "Epoch [ 15/100] | Train: 0.6023/0.8773 | Val: 0.5953/0.8744 | LR: 0.001000\n",
      "Epoch [ 20/100] | Train: 0.5767/0.8903 | Val: 0.5819/0.8826 | LR: 0.001000\n",
      "Epoch [ 25/100] | Train: 0.5525/0.9042 | Val: 0.5729/0.8875 | LR: 0.001000\n",
      "Epoch [ 30/100] | Train: 0.5321/0.9139 | Val: 0.5683/0.8914 | LR: 0.001000\n",
      "Epoch [ 35/100] | Train: 0.5153/0.9253 | Val: 0.5669/0.8890 | LR: 0.001000\n",
      "Epoch [ 40/100] | Train: 0.5078/0.9288 | Val: 0.5623/0.8958 | LR: 0.001000\n",
      "Epoch [ 45/100] | Train: 0.4959/0.9351 | Val: 0.5606/0.8962 | LR: 0.001000\n",
      "Epoch [ 50/100] | Train: 0.4931/0.9363 | Val: 0.5680/0.8957 | LR: 0.001000\n",
      "Epoch [ 55/100] | Train: 0.4736/0.9472 | Val: 0.5577/0.8991 | LR: 0.000500\n",
      "Epoch [ 60/100] | Train: 0.4593/0.9550 | Val: 0.5603/0.8978 | LR: 0.000500\n",
      "Epoch [ 65/100] | Train: 0.4587/0.9558 | Val: 0.5557/0.9004 | LR: 0.000500\n",
      "Epoch [ 70/100] | Train: 0.4544/0.9563 | Val: 0.5569/0.9004 | LR: 0.000500\n",
      "Epoch [ 75/100] | Train: 0.4475/0.9612 | Val: 0.5559/0.9035 | LR: 0.000250\n",
      "Epoch [ 80/100] | Train: 0.4408/0.9647 | Val: 0.5536/0.9021 | LR: 0.000125\n",
      "Epoch [ 85/100] | Train: 0.4433/0.9621 | Val: 0.5522/0.9052 | LR: 0.000125\n",
      "Epoch [ 90/100] | Train: 0.4371/0.9662 | Val: 0.5523/0.9039 | LR: 0.000125\n",
      "Epoch [ 95/100] | Train: 0.4332/0.9681 | Val: 0.5533/0.9043 | LR: 0.000063\n",
      "Epoch [100/100] | Train: 0.4338/0.9671 | Val: 0.5501/0.9034 | LR: 0.000031\n",
      "\n",
      "✓ Entrenamiento completado en 318.19s\n",
      "  Mejor Val Accuracy: 0.9055\n",
      "======================================================================\n",
      "\n",
      "Métricas de raw_medium\n",
      "Accuracy:  0.9019\n",
      "Precision: 0.9016\n",
      "Recall:    0.9019\n",
      "F1-Score:  0.9016\n",
      "Inference: 0.21 ms/batch\n",
      "\n",
      "Métricas por clase:\n",
      "Clase                     Precision    Recall       F1-Score    \n",
      "COVID                     0.8780       0.8986       0.8882      \n",
      "Lung_Opacity              0.8779       0.8371       0.8570      \n",
      "Normal                    0.8699       0.8790       0.8744      \n",
      "Viral Pneumonia           0.9806       0.9928       0.9867      \n",
      "\n",
      "Modelo guardado: mlp_results_opt\\raw\\raw_medium.pth\n",
      "Gráfica guardada: mlp_results_opt\\raw\\raw_medium_history.png\n",
      "Matriz de confusión guardada: mlp_results_opt\\raw\\raw_medium_confusion.png\n",
      "Arquitectura: raw_deep_regularized\n",
      "   Parámetros entrenables: 12,974,692\n",
      "\n",
      "Entrenando raw_deep_regularized\n",
      "Epoch [  5/100] | Train: 0.7337/0.7996 | Val: 0.6684/0.8257 | LR: 0.001000\n",
      "Epoch [ 10/100] | Train: 0.6756/0.8345 | Val: 0.6291/0.8540 | LR: 0.001000\n",
      "Epoch [ 15/100] | Train: 0.6396/0.8545 | Val: 0.6055/0.8661 | LR: 0.001000\n",
      "Epoch [ 20/100] | Train: 0.6030/0.8732 | Val: 0.5858/0.8756 | LR: 0.001000\n",
      "Epoch [ 25/100] | Train: 0.5832/0.8874 | Val: 0.5769/0.8793 | LR: 0.001000\n",
      "Epoch [ 30/100] | Train: 0.5594/0.8991 | Val: 0.5735/0.8873 | LR: 0.001000\n",
      "Epoch [ 35/100] | Train: 0.5496/0.9055 | Val: 0.5765/0.8883 | LR: 0.001000\n",
      "Epoch [ 40/100] | Train: 0.5332/0.9146 | Val: 0.5662/0.8905 | LR: 0.001000\n",
      "Epoch [ 45/100] | Train: 0.5242/0.9193 | Val: 0.5643/0.8945 | LR: 0.001000\n",
      "Epoch [ 50/100] | Train: 0.5159/0.9239 | Val: 0.5630/0.8978 | LR: 0.001000\n",
      "Epoch [ 55/100] | Train: 0.5059/0.9291 | Val: 0.5652/0.8944 | LR: 0.001000\n",
      "Epoch [ 60/100] | Train: 0.4828/0.9406 | Val: 0.5573/0.8993 | LR: 0.000500\n",
      "Epoch [ 65/100] | Train: 0.4771/0.9448 | Val: 0.5618/0.8988 | LR: 0.000500\n",
      "Epoch [ 70/100] | Train: 0.4679/0.9498 | Val: 0.5571/0.9021 | LR: 0.000250\n",
      "Epoch [ 75/100] | Train: 0.4624/0.9527 | Val: 0.5558/0.9009 | LR: 0.000125\n",
      "\n",
      "Early stopping en época 78\n",
      "\n",
      "✓ Entrenamiento completado en 313.93s\n",
      "  Mejor Val Accuracy: 0.9039\n",
      "======================================================================\n",
      "\n",
      "Métricas de raw_deep_regularized\n",
      "Accuracy:  0.9006\n",
      "Precision: 0.9001\n",
      "Recall:    0.9006\n",
      "F1-Score:  0.9003\n",
      "Inference: 0.32 ms/batch\n",
      "\n",
      "Métricas por clase:\n",
      "Clase                     Precision    Recall       F1-Score    \n",
      "COVID                     0.8779       0.8980       0.8878      \n",
      "Lung_Opacity              0.8670       0.8443       0.8555      \n",
      "Normal                    0.8786       0.8666       0.8726      \n",
      "Viral Pneumonia           0.9768       0.9935       0.9851      \n",
      "\n",
      "Modelo guardado: mlp_results_opt\\raw\\raw_deep_regularized.pth\n",
      "Gráfica guardada: mlp_results_opt\\raw\\raw_deep_regularized_history.png\n",
      "Matriz de confusión guardada: mlp_results_opt\\raw\\raw_deep_regularized_confusion.png\n",
      "\n",
      "Resultados guardados: mlp_results_opt\\raw\\comparison.csv\n",
      "Tabla comparativa guardada: mlp_results_opt\\raw\\comparison_table.png\n",
      "RESUMEN - RAW\n",
      "              Modelo  Accuracy  Precision   Recall  F1-Score  Train Time (s)  Inference (ms)   Params  Best Val Acc\n",
      "          raw_medium  0.901897   0.901598 0.901897  0.901581      318.187811        0.205395  8555652      0.905494\n",
      "         raw_shallow  0.901079   0.900709 0.901079  0.900718      172.732121        0.276268  6367684      0.897973\n",
      "raw_deep_regularized  0.900589   0.900100 0.900589  0.900250      313.928853        0.317931 12974692      0.903859\n"
     ]
    }
   ],
   "source": [
    "results_raw = train_all_architectures(\n",
    "        X_train_raw, X_val_raw, X_test_raw,\n",
    "        y_train_raw, y_val_raw, y_test_raw,\n",
    "        data_type='raw',\n",
    "        batch_size=config['batch_size'],\n",
    "        num_epochs=config['num_epochs'],\n",
    "        output_dir=config['output_dir'],\n",
    "        use_augmentation=config['use_augmentation']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
